name: "Local Integration Tests"

env:
  TEST_USERNAME: "test-user"
  TEST_PASSWORD: "P@sswo3d"
  TEST_SUPERADMIN_USER: "test-user-2"
  TEST_SUPERADMIN_PASSWORD: "P@sswo3d-2"
  NEBARI_IMAGE_TAG: "main"
  PYTHON_VERSION: "3.11"

on:
  pull_request:
    paths:
      - ".github/workflows/test_local_integration.yaml"
      - "tests/**"
      - "scripts/**"
      - "src/**"
      - "pyproject.toml"
      - "pytest.ini"
      - ".cirun.yml"
  push:
    branches:
      - main
      - release/\d{4}.\d{1,2}.\d{1,2}
    paths:
      - ".github/workflows/test_local_integration.yaml"
      - "tests/**"
      - "scripts/**"
      - "src/**"
      - "pyproject.toml"
      - "pytest.ini"
      - ".cirun.yml"
  workflow_call:
    inputs:
      pr_number:
        required: true
        type: string
  workflow_dispatch:
  schedule:
    - cron: "0 0 * * MON"

# When the cancel-in-progress: true option is specified, any concurrent jobs or workflows using the same
# concurrency group will cancel both the pending and currently running jobs or workflows. This allows only
# one job or workflow in the concurrency group to be in progress at a time.
# concurrency:
  # group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  # cancel-in-progress: true

jobs:
  test-local-integration:
    runs-on: "cirun-runner--${{ github.run_id }}"
    defaults:
      run:
        shell: bash -l {0}
    steps:
      - name: "Checkout Infrastructure"
      # Pin checkout version due to issue with node24 support on self-hosted runners
        uses: actions/checkout@v4

      - name: "Checkout Nebari repository"
        uses: actions/checkout@v4
        with:
          repository: nebari-dev/nebari
          ref: main
          path: nebari

      # https://kind.sigs.k8s.io/docs/user/known-issues/#pod-errors-due-to-too-many-open-files
      - name: "Update inotify ulimit"
        run: |
          sudo sysctl fs.inotify.max_user_watches=524288
          sudo sysctl fs.inotify.max_user_instances=512

      - name: Setup runner for local deployment
        uses: nebari-dev/nebari/.github/actions/setup-local@main

      - name: Checkout the branch from the PR that triggered the job
        if: ${{ github.event_name == 'issue_comment' }}
        run: |
          hub version
          hub pr checkout ${{ inputs.pr_number }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: conda-incubator/setup-miniconda@v3
        env:
          CONDA: /home/runnerx/miniconda3
        with:
          auto-update-conda: true
          python-version: ${{ env.PYTHON_VERSION }}
          miniconda-version: "latest"
          activate-environment: nebari

      - name: Install JQ
        run: |
          # Wait for apt locks with timeout
          timeout=15
          elapsed=0
          while [ $elapsed -lt $timeout ]; do
            if ! sudo fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 && \
               ! sudo fuser /var/lib/apt/lists/lock >/dev/null 2>&1 && \
               ! sudo fuser /var/lib/dpkg/lock >/dev/null 2>&1; then
              break
            fi
            echo "Waiting for apt locks to be released... (${elapsed}s)"
            sleep 1
            elapsed=$((elapsed + 1))
          done

          if [ $elapsed -ge $timeout ]; then
            echo "Timeout waiting for apt locks"
            exit 1
          fi

          sudo apt-get update
          sudo apt-get install jq -y

      - name: Install Nebari and playwright
        run: |
          pip install -e .[dev]          
          pip install ./nebari[dev]  
          playwright install

          conda env export | tee conda-env.yaml

      - name: Save conda lockfile artifacts
        if: always()
        uses: actions/upload-artifact@v4.3.1
        with:
          name: conda-env-spec
          path: |
            conda-env.yaml

      - name: Initialize Nebari config for local deployment
        id: init
        uses: ./.github/actions/init-local

      - name: Deploy Nebari
        working-directory: ${{ steps.init.outputs.directory }}
        run: nebari deploy --config ${{ steps.init.outputs.config }} --disable-prompt

      - name: Health check
        uses: ./.github/actions/health-check
        with:
          domain: ${{ steps.init.outputs.domain }}

      - name: Create example-users
        working-directory: ${{ steps.init.outputs.directory }}
        run: |
          nebari keycloak add-user --user "${TEST_USERNAME}" -p "${TEST_PASSWORD}" --config ${{ steps.init.outputs.config }}
          nebari keycloak add-user --user "${TEST_SUPERADMIN_USER}" -p "${TEST_SUPERADMIN_PASSWORD}" --config ${{ steps.init.outputs.config }} --groups superadmin
          nebari keycloak list-users --config ${{ steps.init.outputs.config }}

      - name: Await Workloads
        uses: jupyterhub/action-k8s-await-workloads@v3
        with:
          workloads: "" # all
          namespace: "dev"
          timeout: 300
          max-restarts: 3

      ### DEPLOYMENT TESTS
      - name: Deployment Pytests
        env:
          NEBARI_CONFIG_PATH: ${{ steps.init.outputs.config }}
          KEYCLOAK_USERNAME: ${{ env.TEST_USERNAME }}
          KEYCLOAK_PASSWORD: ${{ env.TEST_PASSWORD }}
        run: |
          pytest nebari/tests/tests_deployment/ -v -s

      ### USER-JOURNEY TESTS
      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Playwright Tests
        env:
          KEYCLOAK_USERNAME: ${{ env.TEST_USERNAME }}
          KEYCLOAK_PASSWORD: ${{ env.TEST_PASSWORD }}
          NEBARI_FULL_URL: "https://${{ steps.init.outputs.domain }}/"
        working-directory: nebari/tests/tests_e2e/playwright
        run: |
          # create environment file
          envsubst < .env.tpl > .env
          # run playwright pytest tests in headed mode with the chromium browser
          xvfb-run pytest --browser chromium --slowmo 300 --headed

      - name: Save Playwright recording artifacts
        if: always()
        uses: actions/upload-artifact@v4.3.1
        with:
          name: e2e-playwright
          path: |
            ./nebari/tests/tests_e2e/playwright/videos/

      ### CLEANUP AFTER TESTS
      - name: Cleanup nebari deployment
        # Since this is not critical for most pull requests and takes more than half of the time
        # in the CI, it makes sense to only run on merge to main or workflow_dispatch to speed
        # up feedback cycle
        if: github.ref_name == 'main' || github.event_name == 'workflow_dispatch'
        working-directory: ${{ steps.init.outputs.directory }}
        run: nebari destroy --config ${{ steps.init.outputs.config }} --disable-prompt
